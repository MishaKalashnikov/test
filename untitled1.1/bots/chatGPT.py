import openai
import sqlite3
import asyncio
import logging
from bot import send_message  # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —á–∞—Ç

# üî• API-–∫–ª—é—á OpenAI (–∑–∞–º–µ–Ω–∏ –Ω–∞ —Å–≤–æ–π)
OPENAI_API_KEY = "your-api-key"
openai.api_key = OPENAI_API_KEY

# üìÇ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
DB_PATH = "streamer_voice_log.db"

# üéôÔ∏è –û—á–µ—Ä–µ–¥—å —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
message_queue = asyncio.Queue()

# üî• –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—â–µ–Ω–∏—è (–¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ç—Ä–∏–º–µ—Ä–∞)
chat_contexts = {}

# üõ†Ô∏è –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    filename="chatGPT.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

async def get_latest_voice_logs():
    """üîç –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –ë–î"""
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT streamer, keyword, full_text FROM voice_logs 
            WHERE timestamp >= datetime('now', '-1 minute')
            ORDER BY timestamp DESC
        """)
        logs = cursor.fetchall()
        conn.close()

        for log in logs:
            await message_queue.put(log)  # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {e}")

async def generate_response(streamer, keyword, context):
    """üß† –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç ChatGPT —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –±–µ—Å–µ–¥—ã"""
    if streamer not in chat_contexts:
        chat_contexts[streamer] = [
            {"role": "system", "content": "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –±–æ—Ç, –æ–±—â–∞—é—â–∏–π—Å—è —Å–æ —Å—Ç—Ä–∏–º–µ—Ä–∞–º–∏ –Ω–∞ Twitch."}
        ]

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å—Ç—Ä–∏–º–µ—Ä–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    chat_contexts[streamer].append({"role": "user", "content": f"{streamer} —Å–∫–∞–∑–∞–ª: {context}"})

    # –û–±—Ä–µ–∑–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–æ 10 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (—á—Ç–æ–±—ã –Ω–µ –Ω–∞–∫–∞–ø–ª–∏–≤–∞–ª–æ—Å—å —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ)
    if len(chat_contexts[streamer]) > 10:
        chat_contexts[streamer] = chat_contexts[streamer][-10:]

    try:
        response = await asyncio.to_thread(
            openai.ChatCompletion.create,
            model="gpt-4",
            messages=chat_contexts[streamer],
            max_tokens=50
        )

        reply = response["choices"][0]["message"]["content"]

        # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –æ—Ç–≤–µ—Ç –±–æ—Ç–∞
        chat_contexts[streamer].append({"role": "assistant", "content": reply})

        logging.info(f"üí¨ [ChatGPT] –û—Ç–≤–µ—Ç –¥–ª—è {streamer}: {reply}")
        return reply
    except openai.error.OpenAIError as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI: {e}")
        return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."

async def process_messages(sock):
    """üì© –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—á–µ—Ä–µ–¥—å —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Ç–≤–µ—Ç—ã"""
    while True:
        streamer, keyword, context = await message_queue.get()  # –ë–µ—Ä—ë–º —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ –æ—á–µ—Ä–µ–¥–∏
        reply = await generate_response(streamer, keyword, context)  # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        if reply:
            await send_message(sock, streamer, reply)  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —á–∞—Ç
        await asyncio.sleep(2)  # –ê–Ω—Ç–∏—Å–ø–∞–º (2 —Å–µ–∫—É–Ω–¥—ã)
